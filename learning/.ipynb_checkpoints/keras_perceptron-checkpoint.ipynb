{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汎用ライブラリのimport\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras用ライブラリ\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自作ライブラリのimport\n",
    "if os.environ['BR_HOME']+\"/boatrace\" not in sys.path:\n",
    "    sys.path.append(os.environ['BR_HOME']+\"/boatrace\")\n",
    "#print(sys.path)\n",
    "\n",
    "from setup.myUtil import dbHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 舟券の配列を取得\n",
    "funakenList=[]\n",
    "with open(os.environ['BR_HOME']+'/boatrace/config/3t_list.dat') as f:\n",
    "    reader=csv.reader(f)\n",
    "    for row in reader:\n",
    "        funakenList.append(row)\n",
    "funakenID = [i for i in range(120)]\n",
    "funakenDict=dict(zip(funakenList[0],funakenID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析期間の指定は一旦ここでまとめてみる。\n",
    "simStartDate=\"20180101\"\n",
    "simEndDate=\"20181231\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbh=dbHandler.getDBHandle()\n",
    "#dbHandler.closeDBHandle(dbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simdata: 54083\n"
     ]
    }
   ],
   "source": [
    "# データを取得\n",
    "with dbh.cursor() as cursor:\n",
    "    sel_sql = \"select * from raceabst_forml_rentai_v \\\n",
    "               where raceDate between '%s' and '%s' \\\n",
    "               order by raceId \"\\\n",
    "               % (simStartDate,simEndDate)\n",
    "    cursor.execute(sel_sql)\n",
    "    loadList=cursor.fetchall()\n",
    "print(\"simdata:\",len(loadList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funaken</th>\n",
       "      <th>l1Fcnt</th>\n",
       "      <th>l1boat2r</th>\n",
       "      <th>l1boat3r</th>\n",
       "      <th>l1motor2r</th>\n",
       "      <th>l1motor3r</th>\n",
       "      <th>l1oldavgstdev</th>\n",
       "      <th>l1oldavgsttime</th>\n",
       "      <th>l1oldrank1</th>\n",
       "      <th>l1oldrank2</th>\n",
       "      <th>...</th>\n",
       "      <th>l6oldrank4</th>\n",
       "      <th>l6oldrank5</th>\n",
       "      <th>l6oldrank6</th>\n",
       "      <th>l6rank</th>\n",
       "      <th>l6score</th>\n",
       "      <th>odds</th>\n",
       "      <th>raceDate</th>\n",
       "      <th>raceId</th>\n",
       "      <th>raceWaveHeight</th>\n",
       "      <th>raceWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-1-3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>0.5092</td>\n",
       "      <td>-0.01513</td>\n",
       "      <td>0.17280</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20180101-06-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-1-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.21640</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.886552</td>\n",
       "      <td>26.2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20180101-06-02</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-5-4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.4108</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.19652</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.580764</td>\n",
       "      <td>99.2</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20180101-06-03</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-5-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>-0.01063</td>\n",
       "      <td>0.17090</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.583266</td>\n",
       "      <td>16.8</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20180101-06-04</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-1-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.470489</td>\n",
       "      <td>51.5</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>20180101-06-05</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  funaken  l1Fcnt  l1boat2r  l1boat3r  l1motor2r  l1motor3r  l1oldavgstdev  \\\n",
       "0   2-1-3       1    0.3636    0.5152     0.3558     0.5092       -0.01513   \n",
       "1   2-1-6       0    0.2462    0.4462     0.3466     0.4830        0.02080   \n",
       "2   3-5-4       0    0.3692    0.5231     0.3135     0.4108        0.00215   \n",
       "3   1-5-2       0    0.4308    0.6308     0.3676     0.5514       -0.01063   \n",
       "4   4-1-3       0    0.3636    0.5152     0.4469     0.5754        0.00412   \n",
       "\n",
       "   l1oldavgsttime  l1oldrank1  l1oldrank2  ...  l6oldrank4  l6oldrank5  \\\n",
       "0         0.17280        0.19        0.14  ...        0.13        0.15   \n",
       "1         0.21640        0.08        0.28  ...        0.20        0.17   \n",
       "2         0.19652        0.03        0.05  ...        0.11        0.15   \n",
       "3         0.17090        0.26        0.27  ...        0.20        0.13   \n",
       "4         0.17030        0.19        0.18  ...        0.06        0.09   \n",
       "\n",
       "   l6oldrank6  l6rank   l6score  odds    raceDate          raceId  \\\n",
       "0        0.14      B2  0.851669  30.9  2018-01-01  20180101-06-01   \n",
       "1        0.13      B1  0.886552  26.2  2018-01-01  20180101-06-02   \n",
       "2        0.24      B1  0.580764  99.2  2018-01-01  20180101-06-03   \n",
       "3        0.14      B1  0.583266  16.8  2018-01-01  20180101-06-04   \n",
       "4        0.07      B2  0.470489  51.5  2018-01-01  20180101-06-05   \n",
       "\n",
       "   raceWaveHeight  raceWindSpeed  \n",
       "0               3            5.0  \n",
       "1               3            5.0  \n",
       "2               3            5.0  \n",
       "3               3            5.0  \n",
       "4               3            5.0  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.io.json.json_normalize(loadList)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1Fcnt</th>\n",
       "      <th>l1boat2r</th>\n",
       "      <th>l1boat3r</th>\n",
       "      <th>l1motor2r</th>\n",
       "      <th>l1motor3r</th>\n",
       "      <th>l1oldavgstdev</th>\n",
       "      <th>l1oldavgsttime</th>\n",
       "      <th>l1oldrank1</th>\n",
       "      <th>l1oldrank2</th>\n",
       "      <th>l1oldrank3</th>\n",
       "      <th>...</th>\n",
       "      <th>l6oldavgsttime</th>\n",
       "      <th>l6oldrank1</th>\n",
       "      <th>l6oldrank2</th>\n",
       "      <th>l6oldrank3</th>\n",
       "      <th>l6oldrank4</th>\n",
       "      <th>l6oldrank5</th>\n",
       "      <th>l6oldrank6</th>\n",
       "      <th>l6rank</th>\n",
       "      <th>raceWaveHeight</th>\n",
       "      <th>raceWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>0.5092</td>\n",
       "      <td>-0.01513</td>\n",
       "      <td>0.17280</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>0.02080</td>\n",
       "      <td>0.21640</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1608</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.4108</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.19652</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>-0.01063</td>\n",
       "      <td>0.17090</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>0.4469</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.17030</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1887</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   l1Fcnt  l1boat2r  l1boat3r  l1motor2r  l1motor3r  l1oldavgstdev  \\\n",
       "0       1    0.3636    0.5152     0.3558     0.5092       -0.01513   \n",
       "1       0    0.2462    0.4462     0.3466     0.4830        0.02080   \n",
       "2       0    0.3692    0.5231     0.3135     0.4108        0.00215   \n",
       "3       0    0.4308    0.6308     0.3676     0.5514       -0.01063   \n",
       "4       0    0.3636    0.5152     0.4469     0.5754        0.00412   \n",
       "\n",
       "   l1oldavgsttime  l1oldrank1  l1oldrank2  l1oldrank3  ...  l6oldavgsttime  \\\n",
       "0         0.17280        0.19        0.14        0.15  ...          0.2102   \n",
       "1         0.21640        0.08        0.28        0.21  ...          0.1608   \n",
       "2         0.19652        0.03        0.05        0.05  ...          0.3131   \n",
       "3         0.17090        0.26        0.27        0.14  ...          0.1769   \n",
       "4         0.17030        0.19        0.18        0.12  ...          0.1887   \n",
       "\n",
       "   l6oldrank1  l6oldrank2  l6oldrank3  l6oldrank4  l6oldrank5  l6oldrank6  \\\n",
       "0        0.01        0.03        0.05        0.13        0.15        0.14   \n",
       "1        0.08        0.15        0.27        0.20        0.17        0.13   \n",
       "2        0.13        0.23        0.14        0.11        0.15        0.24   \n",
       "3        0.13        0.17        0.23        0.20        0.13        0.14   \n",
       "4        0.00        0.01        0.00        0.06        0.09        0.07   \n",
       "\n",
       "   l6rank  raceWaveHeight  raceWindSpeed  \n",
       "0       3               3            5.0  \n",
       "1       2               3            5.0  \n",
       "2       2               3            5.0  \n",
       "3       2               3            5.0  \n",
       "4       3               3            5.0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力のデータ整形\n",
    "xdf=df.drop(['funaken','odds','raceId','raceDate'],axis=1)\n",
    "# オッズから作ったスコアは効きすぎるので捨ててみる\n",
    "xdf=xdf.drop(['l1score','l2score','l3score','l4score','l5score','l6score'],axis=1)\n",
    "#xdf=xdf.drop(['l1Fcnt','l2Fcnt','l3Fcnt','l4Fcnt','l5Fcnt','l6Fcnt'],axis=1)\n",
    "#xdf=xdf.drop(['l1oldavgstdev','l2oldavgstdev','l3oldavgstdev','l4oldavgstdev','l5oldavgstdev','l6oldavgstdev'],axis=1)\n",
    "\n",
    "rankLabel=LabelEncoder()\n",
    "rankLabel=rankLabel.fit(xdf['l1rank'])\n",
    "xdf['l1rank']=rankLabel.transform(xdf['l1rank'])\n",
    "xdf['l2rank']=rankLabel.transform(xdf['l2rank'])\n",
    "xdf['l3rank']=rankLabel.transform(xdf['l3rank'])\n",
    "xdf['l4rank']=rankLabel.transform(xdf['l4rank'])\n",
    "xdf['l5rank']=rankLabel.transform(xdf['l5rank'])\n",
    "xdf['l6rank']=rankLabel.transform(xdf['l6rank'])\n",
    "xdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   l1boat2r\n",
      "0  0.385434\n",
      "1 -0.702883\n"
     ]
    }
   ],
   "source": [
    "# validation向けに平均値、標準偏差を出しておく\n",
    "zscore_param=xdf.describe()\n",
    "# 変換の方法はこちら。\n",
    "print( (xdf.loc[\"0\":\"1\",[\"l1boat2r\"] ]-zscore_param['l1boat2r']['mean'])/zscore_param['l1boat2r']['std'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizeしておく\n",
    "# ★validationの時に要注意。\n",
    "xdf=xdf.apply(scipy.stats.zscore, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1Fcnt</th>\n",
       "      <th>l1boat2r</th>\n",
       "      <th>l1boat3r</th>\n",
       "      <th>l1motor2r</th>\n",
       "      <th>l1motor3r</th>\n",
       "      <th>l1oldavgstdev</th>\n",
       "      <th>l1oldavgsttime</th>\n",
       "      <th>l1oldrank1</th>\n",
       "      <th>l1oldrank2</th>\n",
       "      <th>l1oldrank3</th>\n",
       "      <th>...</th>\n",
       "      <th>l6oldavgsttime</th>\n",
       "      <th>l6oldrank1</th>\n",
       "      <th>l6oldrank2</th>\n",
       "      <th>l6oldrank3</th>\n",
       "      <th>l6oldrank4</th>\n",
       "      <th>l6oldrank5</th>\n",
       "      <th>l6oldrank6</th>\n",
       "      <th>l6rank</th>\n",
       "      <th>raceWaveHeight</th>\n",
       "      <th>raceWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.383492</td>\n",
       "      <td>0.385438</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>0.274803</td>\n",
       "      <td>0.165048</td>\n",
       "      <td>-0.334426</td>\n",
       "      <td>-0.178330</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>-0.712480</td>\n",
       "      <td>-0.489666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492243</td>\n",
       "      <td>-1.355948</td>\n",
       "      <td>-1.626986</td>\n",
       "      <td>-1.592777</td>\n",
       "      <td>-0.458801</td>\n",
       "      <td>-0.234887</td>\n",
       "      <td>-0.344661</td>\n",
       "      <td>1.590847</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>1.162865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.397120</td>\n",
       "      <td>-0.702890</td>\n",
       "      <td>-0.266202</td>\n",
       "      <td>0.193452</td>\n",
       "      <td>-0.018344</td>\n",
       "      <td>0.602493</td>\n",
       "      <td>0.778055</td>\n",
       "      <td>-1.147828</td>\n",
       "      <td>1.791374</td>\n",
       "      <td>0.795856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491896</td>\n",
       "      <td>-0.669148</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>1.795791</td>\n",
       "      <td>0.702825</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>-0.411413</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>1.162865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.397120</td>\n",
       "      <td>0.437351</td>\n",
       "      <td>0.295136</td>\n",
       "      <td>-0.099231</td>\n",
       "      <td>-0.523721</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.341979</td>\n",
       "      <td>-1.668863</td>\n",
       "      <td>-2.322101</td>\n",
       "      <td>-2.632204</td>\n",
       "      <td>...</td>\n",
       "      <td>2.542200</td>\n",
       "      <td>-0.178577</td>\n",
       "      <td>1.071580</td>\n",
       "      <td>-0.206545</td>\n",
       "      <td>-0.790694</td>\n",
       "      <td>-0.234887</td>\n",
       "      <td>0.322868</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>1.162865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.397120</td>\n",
       "      <td>1.008399</td>\n",
       "      <td>1.081301</td>\n",
       "      <td>0.379143</td>\n",
       "      <td>0.460434</td>\n",
       "      <td>-0.217083</td>\n",
       "      <td>-0.220007</td>\n",
       "      <td>0.727898</td>\n",
       "      <td>1.612528</td>\n",
       "      <td>-0.703920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171154</td>\n",
       "      <td>-0.178577</td>\n",
       "      <td>0.262010</td>\n",
       "      <td>1.179687</td>\n",
       "      <td>0.702825</td>\n",
       "      <td>-0.527226</td>\n",
       "      <td>-0.344661</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>1.162865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.397120</td>\n",
       "      <td>0.385438</td>\n",
       "      <td>0.237469</td>\n",
       "      <td>1.080345</td>\n",
       "      <td>0.628426</td>\n",
       "      <td>0.167541</td>\n",
       "      <td>-0.233168</td>\n",
       "      <td>-0.001551</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>-1.132427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063923</td>\n",
       "      <td>-1.454063</td>\n",
       "      <td>-1.896843</td>\n",
       "      <td>-2.362906</td>\n",
       "      <td>-1.620427</td>\n",
       "      <td>-1.111903</td>\n",
       "      <td>-0.811931</td>\n",
       "      <td>1.590847</td>\n",
       "      <td>0.215616</td>\n",
       "      <td>1.162865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     l1Fcnt  l1boat2r  l1boat3r  l1motor2r  l1motor3r  l1oldavgstdev  \\\n",
       "0  2.383492  0.385438  0.237469   0.274803   0.165048      -0.334426   \n",
       "1 -0.397120 -0.702890 -0.266202   0.193452  -0.018344       0.602493   \n",
       "2 -0.397120  0.437351  0.295136  -0.099231  -0.523721       0.116171   \n",
       "3 -0.397120  1.008399  1.081301   0.379143   0.460434      -0.217083   \n",
       "4 -0.397120  0.385438  0.237469   1.080345   0.628426       0.167541   \n",
       "\n",
       "   l1oldavgsttime  l1oldrank1  l1oldrank2  l1oldrank3  ...  l6oldavgsttime  \\\n",
       "0       -0.178330   -0.001551   -0.712480   -0.489666  ...        0.492243   \n",
       "1        0.778055   -1.147828    1.791374    0.795856  ...       -0.491896   \n",
       "2        0.341979   -1.668863   -2.322101   -2.632204  ...        2.542200   \n",
       "3       -0.220007    0.727898    1.612528   -0.703920  ...       -0.171154   \n",
       "4       -0.233168   -0.001551    0.002907   -1.132427  ...        0.063923   \n",
       "\n",
       "   l6oldrank1  l6oldrank2  l6oldrank3  l6oldrank4  l6oldrank5  l6oldrank6  \\\n",
       "0   -1.355948   -1.626986   -1.592777   -0.458801   -0.234887   -0.344661   \n",
       "1   -0.669148   -0.007846    1.795791    0.702825    0.057451   -0.411413   \n",
       "2   -0.178577    1.071580   -0.206545   -0.790694   -0.234887    0.322868   \n",
       "3   -0.178577    0.262010    1.179687    0.702825   -0.527226   -0.344661   \n",
       "4   -1.454063   -1.896843   -2.362906   -1.620427   -1.111903   -0.811931   \n",
       "\n",
       "     l6rank  raceWaveHeight  raceWindSpeed  \n",
       "0  1.590847        0.215616       1.162865  \n",
       "1  0.545545        0.215616       1.162865  \n",
       "2  0.545545        0.215616       1.162865  \n",
       "3  0.545545        0.215616       1.162865  \n",
       "4  1.590847        0.215616       1.162865  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# ファイルから作った辞書で変換する\n",
    "ydf=df['funaken']\n",
    "ydf=pd.DataFrame(ydf.replace(funakenDict))\n",
    "ydf['funaken']=ydf['funaken'].astype(int)\n",
    "#ydf.head()\n",
    "\n",
    "# ydfはone-hotにしておく。\n",
    "y=np.eye(120)[ydf['funaken']]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30.9  26.2  99.2 ... 267.6  14.4  10.7]\n",
      "['20180101-06-01' '20180101-06-02' '20180101-06-03' ... '20181231-24-10'\n",
      " '20181231-24-11' '20181231-24-12']\n"
     ]
    }
   ],
   "source": [
    "# 重み付けのため、オッズのリストを作る\n",
    "odf=df['odds'].values\n",
    "raceId_df=df['raceId'].values\n",
    "#odf=pd.DataFrame(df['odds'])\n",
    "#odf.describe()\n",
    "print(odf)\n",
    "print(raceId_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train,X_test: 40562 13521\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "y_train,y_test: 40562 13521\n",
      "<class 'numpy.ndarray'>\n",
      "o_train,o_test: 40562 13521\n",
      "<class 'numpy.ndarray'>\n",
      "raceId_train,raceId_test: 40562 13521\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#train/testを分割\n",
    "X_train, X_test, y_train, y_test,o_train,o_test,raceId_train,raceId_test = train_test_split(xdf, y,odf,raceId_df)\n",
    "print(\"X_train,X_test:\",len(X_train),len(X_test))\n",
    "print(type(X_train))\n",
    "print(\"y_train,y_test:\",len(y_train),len(y_test))\n",
    "print(type(y_train))\n",
    "print(\"o_train,o_test:\",len(o_train),len(o_test))\n",
    "print(type(o_train))\n",
    "print(\"raceId_train,raceId_test:\",len(raceId_train),len(raceId_test))\n",
    "print(type(o_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class\n",
    "class my_Net:\n",
    "    def __init__(self):\n",
    "        # 整数パラメータの保証\n",
    "        in_hidden_units = int(1124)\n",
    "        in_layer_num = int(3.24)\n",
    "        assert(type(in_hidden_units)== int)\n",
    "        assert(type(in_layer_num)== int )\n",
    "    \n",
    "        self.Epoch = 400\n",
    "        #self.Batch_size = 4000\n",
    "        self.Batch_size = 10000\n",
    "        self.Verbose = 1 #ログの出力モード切替 : 1 プログレスバーで表示\n",
    "        self.output_size = 120\n",
    "        self.optimize = SGD() #確率的勾配下降法\n",
    "        #self.hidden_units = 128\n",
    "        #self.hidden_units = 256\n",
    "        self.hidden_units = in_hidden_units\n",
    "        self.layer_num = in_layer_num\n",
    "        self.Validation_split = 0.2 #訓練データの中で検証データとして扱う割合\n",
    "        #self.Reshape = 28 * 28\n",
    "\n",
    "        \n",
    "        self.model = Sequential()\n",
    " \n",
    "    def make_net(self):\n",
    "        self.model.add(Dense(self.hidden_units, input_shape=(86,)))\n",
    "        self.model.add(Activation(\"relu\"))\n",
    "        for i in range(self.layer_num):\n",
    "            self.model.add(Dense(self.hidden_units))\n",
    "            self.model.add(Activation(\"relu\"))\n",
    "        self.model.add(Dense(self.output_size))\n",
    "        self.model.add(Activation(\"softmax\"))\n",
    "        self.model.summary()\n",
    "        \n",
    "    def model_compile(self):\n",
    "        self.model.compile(loss=\"categorical_crossentropy\", #交差エントロピー誤差関数\n",
    "                           optimizer=self.optimize,#確率的勾配下降法\n",
    "                           metrics=[\"accuracy\"])\n",
    " \n",
    "    def make_model(self):\n",
    "        self.make_net()\n",
    "        self.model_compile()\n",
    " \n",
    "    def train(self, x, t):\n",
    "        self.model.fit(x, t, batch_size=self.Batch_size,\n",
    "                       epochs=self.Epoch,\n",
    "                       verbose=self.Verbose,\n",
    "                       validation_split=self.Validation_split)\n",
    " \n",
    "    def score(self, x, t):\n",
    "        return self.model.evaluate(x, t, verbose=self.Verbose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0817 06:33:34.839357 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0817 06:33:34.840661 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0817 06:33:34.842578 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0817 06:33:34.894895 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0817 06:33:34.904984 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1124)              97788     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1124)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1124)              1264500   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1124)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1124)              1264500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1124)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1124)              1264500   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1124)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 120)               135000    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 120)               0         \n",
      "=================================================================\n",
      "Total params: 4,026,288\n",
      "Trainable params: 4,026,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0817 06:33:35.004822 139923477436224 deprecation.py:323] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0817 06:33:35.053677 139923477436224 deprecation_wrapper.py:119] From /home/ec2-user/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32449 samples, validate on 8113 samples\n",
      "Epoch 1/400\n",
      "32449/32449 [==============================] - 9s 275us/step - loss: 4.7634 - acc: 0.0441 - val_loss: 4.7139 - val_acc: 0.0675\n",
      "Epoch 2/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.6640 - acc: 0.0655 - val_loss: 4.6120 - val_acc: 0.0675\n",
      "Epoch 3/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.5548 - acc: 0.0655 - val_loss: 4.5024 - val_acc: 0.0675\n",
      "Epoch 4/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.4489 - acc: 0.0655 - val_loss: 4.4130 - val_acc: 0.0675\n",
      "Epoch 5/400\n",
      "32449/32449 [==============================] - 11s 342us/step - loss: 4.3713 - acc: 0.0656 - val_loss: 4.3554 - val_acc: 0.0677\n",
      "Epoch 6/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 4.3213 - acc: 0.0657 - val_loss: 4.3187 - val_acc: 0.0679\n",
      "Epoch 7/400\n",
      "32449/32449 [==============================] - 12s 366us/step - loss: 4.2888 - acc: 0.0657 - val_loss: 4.2949 - val_acc: 0.0679\n",
      "Epoch 8/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 4.2668 - acc: 0.0662 - val_loss: 4.2787 - val_acc: 0.0677\n",
      "Epoch 9/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 4.2509 - acc: 0.0665 - val_loss: 4.2664 - val_acc: 0.0682\n",
      "Epoch 10/400\n",
      "32449/32449 [==============================] - 12s 379us/step - loss: 4.2383 - acc: 0.0665 - val_loss: 4.2566 - val_acc: 0.0687\n",
      "Epoch 11/400\n",
      "32449/32449 [==============================] - 12s 372us/step - loss: 4.2279 - acc: 0.0667 - val_loss: 4.2481 - val_acc: 0.0688\n",
      "Epoch 12/400\n",
      "32449/32449 [==============================] - 12s 372us/step - loss: 4.2189 - acc: 0.0671 - val_loss: 4.2409 - val_acc: 0.0688\n",
      "Epoch 13/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 4.2108 - acc: 0.0675 - val_loss: 4.2343 - val_acc: 0.0695\n",
      "Epoch 14/400\n",
      "32449/32449 [==============================] - 12s 373us/step - loss: 4.2034 - acc: 0.0679 - val_loss: 4.2283 - val_acc: 0.0706\n",
      "Epoch 15/400\n",
      "32449/32449 [==============================] - 12s 370us/step - loss: 4.1966 - acc: 0.0696 - val_loss: 4.2225 - val_acc: 0.0699\n",
      "Epoch 16/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 4.1901 - acc: 0.0694 - val_loss: 4.2172 - val_acc: 0.0705\n",
      "Epoch 17/400\n",
      "32449/32449 [==============================] - 13s 398us/step - loss: 4.1840 - acc: 0.0705 - val_loss: 4.2117 - val_acc: 0.0717\n",
      "Epoch 18/400\n",
      "32449/32449 [==============================] - 13s 385us/step - loss: 4.1781 - acc: 0.0709 - val_loss: 4.2071 - val_acc: 0.0717\n",
      "Epoch 19/400\n",
      "32449/32449 [==============================] - 12s 357us/step - loss: 4.1725 - acc: 0.0710 - val_loss: 4.2022 - val_acc: 0.0746\n",
      "Epoch 20/400\n",
      "32449/32449 [==============================] - 11s 336us/step - loss: 4.1670 - acc: 0.0717 - val_loss: 4.1975 - val_acc: 0.0741\n",
      "Epoch 21/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.1615 - acc: 0.0724 - val_loss: 4.1930 - val_acc: 0.0754\n",
      "Epoch 22/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1564 - acc: 0.0737 - val_loss: 4.1886 - val_acc: 0.0761\n",
      "Epoch 23/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1512 - acc: 0.0744 - val_loss: 4.1842 - val_acc: 0.0781\n",
      "Epoch 24/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1462 - acc: 0.0751 - val_loss: 4.1799 - val_acc: 0.0779\n",
      "Epoch 25/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1412 - acc: 0.0764 - val_loss: 4.1757 - val_acc: 0.0777\n",
      "Epoch 26/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.1362 - acc: 0.0762 - val_loss: 4.1717 - val_acc: 0.0794\n",
      "Epoch 27/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1314 - acc: 0.0780 - val_loss: 4.1676 - val_acc: 0.0799\n",
      "Epoch 28/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1264 - acc: 0.0787 - val_loss: 4.1631 - val_acc: 0.0789\n",
      "Epoch 29/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 4.1215 - acc: 0.0796 - val_loss: 4.1594 - val_acc: 0.0797\n",
      "Epoch 30/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1167 - acc: 0.0813 - val_loss: 4.1552 - val_acc: 0.0799\n",
      "Epoch 31/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1117 - acc: 0.0819 - val_loss: 4.1507 - val_acc: 0.0800\n",
      "Epoch 32/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1068 - acc: 0.0816 - val_loss: 4.1470 - val_acc: 0.0795\n",
      "Epoch 33/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.1020 - acc: 0.0831 - val_loss: 4.1429 - val_acc: 0.0800\n",
      "Epoch 34/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0970 - acc: 0.0842 - val_loss: 4.1390 - val_acc: 0.0797\n",
      "Epoch 35/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 4.0922 - acc: 0.0840 - val_loss: 4.1348 - val_acc: 0.0799\n",
      "Epoch 36/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0873 - acc: 0.0855 - val_loss: 4.1309 - val_acc: 0.0809\n",
      "Epoch 37/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0823 - acc: 0.0857 - val_loss: 4.1268 - val_acc: 0.0805\n",
      "Epoch 38/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0774 - acc: 0.0859 - val_loss: 4.1224 - val_acc: 0.0801\n",
      "Epoch 39/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0724 - acc: 0.0868 - val_loss: 4.1186 - val_acc: 0.0817\n",
      "Epoch 40/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0676 - acc: 0.0879 - val_loss: 4.1144 - val_acc: 0.0820\n",
      "Epoch 41/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.0627 - acc: 0.0883 - val_loss: 4.1106 - val_acc: 0.0811\n",
      "Epoch 42/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0579 - acc: 0.0886 - val_loss: 4.1065 - val_acc: 0.0832\n",
      "Epoch 43/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0529 - acc: 0.0891 - val_loss: 4.1025 - val_acc: 0.0818\n",
      "Epoch 44/400\n",
      "32449/32449 [==============================] - 8s 247us/step - loss: 4.0481 - acc: 0.0891 - val_loss: 4.0987 - val_acc: 0.0810\n",
      "Epoch 45/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0432 - acc: 0.0889 - val_loss: 4.0945 - val_acc: 0.0826\n",
      "Epoch 46/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0385 - acc: 0.0903 - val_loss: 4.0903 - val_acc: 0.0821\n",
      "Epoch 47/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0336 - acc: 0.0899 - val_loss: 4.0866 - val_acc: 0.0828\n",
      "Epoch 48/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0290 - acc: 0.0902 - val_loss: 4.0831 - val_acc: 0.0815\n",
      "Epoch 49/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 4.0242 - acc: 0.0903 - val_loss: 4.0792 - val_acc: 0.0825\n",
      "Epoch 50/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 4.0196 - acc: 0.0914 - val_loss: 4.0754 - val_acc: 0.0807\n",
      "Epoch 51/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0148 - acc: 0.0923 - val_loss: 4.0716 - val_acc: 0.0810\n",
      "Epoch 52/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0102 - acc: 0.0921 - val_loss: 4.0685 - val_acc: 0.0816\n",
      "Epoch 53/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0057 - acc: 0.0922 - val_loss: 4.0643 - val_acc: 0.0811\n",
      "Epoch 54/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 4.0012 - acc: 0.0925 - val_loss: 4.0613 - val_acc: 0.0805\n",
      "Epoch 55/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.9968 - acc: 0.0928 - val_loss: 4.0576 - val_acc: 0.0818\n",
      "Epoch 56/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9923 - acc: 0.0939 - val_loss: 4.0540 - val_acc: 0.0823\n",
      "Epoch 57/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9881 - acc: 0.0929 - val_loss: 4.0508 - val_acc: 0.0815\n",
      "Epoch 58/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9837 - acc: 0.0936 - val_loss: 4.0480 - val_acc: 0.0833\n",
      "Epoch 59/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.9792 - acc: 0.0947 - val_loss: 4.0444 - val_acc: 0.0830\n",
      "Epoch 60/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9751 - acc: 0.0936 - val_loss: 4.0409 - val_acc: 0.0821\n",
      "Epoch 61/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9709 - acc: 0.0942 - val_loss: 4.0378 - val_acc: 0.0828\n",
      "Epoch 62/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9668 - acc: 0.0947 - val_loss: 4.0349 - val_acc: 0.0846\n",
      "Epoch 63/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9627 - acc: 0.0949 - val_loss: 4.0323 - val_acc: 0.0825\n",
      "Epoch 64/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9587 - acc: 0.0940 - val_loss: 4.0301 - val_acc: 0.0832\n",
      "Epoch 65/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9548 - acc: 0.0953 - val_loss: 4.0260 - val_acc: 0.0834\n",
      "Epoch 66/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.9507 - acc: 0.0949 - val_loss: 4.0230 - val_acc: 0.0830\n",
      "Epoch 67/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9470 - acc: 0.0957 - val_loss: 4.0206 - val_acc: 0.0842\n",
      "Epoch 68/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9431 - acc: 0.0963 - val_loss: 4.0182 - val_acc: 0.0842\n",
      "Epoch 69/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9395 - acc: 0.0961 - val_loss: 4.0156 - val_acc: 0.0839\n",
      "Epoch 70/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9359 - acc: 0.0963 - val_loss: 4.0128 - val_acc: 0.0838\n",
      "Epoch 71/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9323 - acc: 0.0967 - val_loss: 4.0105 - val_acc: 0.0846\n",
      "Epoch 72/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9287 - acc: 0.0965 - val_loss: 4.0086 - val_acc: 0.0860\n",
      "Epoch 73/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9254 - acc: 0.0974 - val_loss: 4.0053 - val_acc: 0.0857\n",
      "Epoch 74/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.9220 - acc: 0.0976 - val_loss: 4.0023 - val_acc: 0.0854\n",
      "Epoch 75/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9183 - acc: 0.0984 - val_loss: 4.0000 - val_acc: 0.0858\n",
      "Epoch 76/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9152 - acc: 0.0986 - val_loss: 3.9984 - val_acc: 0.0859\n",
      "Epoch 77/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.9120 - acc: 0.0977 - val_loss: 3.9970 - val_acc: 0.0867\n",
      "Epoch 78/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.9088 - acc: 0.0977 - val_loss: 3.9943 - val_acc: 0.0868\n",
      "Epoch 79/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.9057 - acc: 0.0990 - val_loss: 3.9924 - val_acc: 0.0859\n",
      "Epoch 80/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.9028 - acc: 0.0990 - val_loss: 3.9907 - val_acc: 0.0859\n",
      "Epoch 81/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.8996 - acc: 0.0992 - val_loss: 3.9884 - val_acc: 0.0858\n",
      "Epoch 82/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8966 - acc: 0.0995 - val_loss: 3.9863 - val_acc: 0.0849\n",
      "Epoch 83/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8936 - acc: 0.0992 - val_loss: 3.9849 - val_acc: 0.0874\n",
      "Epoch 84/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8909 - acc: 0.1004 - val_loss: 3.9829 - val_acc: 0.0860\n",
      "Epoch 85/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8882 - acc: 0.0994 - val_loss: 3.9813 - val_acc: 0.0848\n",
      "Epoch 86/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.8856 - acc: 0.0997 - val_loss: 3.9794 - val_acc: 0.0885\n",
      "Epoch 87/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8828 - acc: 0.1001 - val_loss: 3.9789 - val_acc: 0.0858\n",
      "Epoch 88/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8799 - acc: 0.1003 - val_loss: 3.9771 - val_acc: 0.0853\n",
      "Epoch 89/400\n",
      "32449/32449 [==============================] - 8s 246us/step - loss: 3.8774 - acc: 0.1016 - val_loss: 3.9758 - val_acc: 0.0863\n",
      "Epoch 90/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8749 - acc: 0.1017 - val_loss: 3.9743 - val_acc: 0.0878\n",
      "Epoch 91/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8725 - acc: 0.1013 - val_loss: 3.9719 - val_acc: 0.0865\n",
      "Epoch 92/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8700 - acc: 0.1017 - val_loss: 3.9711 - val_acc: 0.0879\n",
      "Epoch 93/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8676 - acc: 0.1016 - val_loss: 3.9692 - val_acc: 0.0862\n",
      "Epoch 94/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8652 - acc: 0.1013 - val_loss: 3.9687 - val_acc: 0.0859\n",
      "Epoch 95/400\n",
      "32449/32449 [==============================] - 8s 247us/step - loss: 3.8629 - acc: 0.1023 - val_loss: 3.9678 - val_acc: 0.0859\n",
      "Epoch 96/400\n",
      "32449/32449 [==============================] - 9s 270us/step - loss: 3.8605 - acc: 0.1036 - val_loss: 3.9664 - val_acc: 0.0863\n",
      "Epoch 97/400\n",
      "32449/32449 [==============================] - 12s 373us/step - loss: 3.8583 - acc: 0.1016 - val_loss: 3.9655 - val_acc: 0.0858\n",
      "Epoch 98/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 3.8562 - acc: 0.1024 - val_loss: 3.9632 - val_acc: 0.0855\n",
      "Epoch 99/400\n",
      "32449/32449 [==============================] - 12s 365us/step - loss: 3.8539 - acc: 0.1035 - val_loss: 3.9628 - val_acc: 0.0858\n",
      "Epoch 100/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 3.8519 - acc: 0.1034 - val_loss: 3.9626 - val_acc: 0.0864\n",
      "Epoch 101/400\n",
      "32449/32449 [==============================] - 12s 367us/step - loss: 3.8497 - acc: 0.1035 - val_loss: 3.9605 - val_acc: 0.0860\n",
      "Epoch 102/400\n",
      "32449/32449 [==============================] - 12s 374us/step - loss: 3.8478 - acc: 0.1034 - val_loss: 3.9590 - val_acc: 0.0869\n",
      "Epoch 103/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 3.8456 - acc: 0.1035 - val_loss: 3.9594 - val_acc: 0.0875\n",
      "Epoch 104/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 3.8436 - acc: 0.1039 - val_loss: 3.9580 - val_acc: 0.0867\n",
      "Epoch 105/400\n",
      "32449/32449 [==============================] - 12s 368us/step - loss: 3.8417 - acc: 0.1043 - val_loss: 3.9575 - val_acc: 0.0854\n",
      "Epoch 106/400\n",
      "32449/32449 [==============================] - 12s 383us/step - loss: 3.8398 - acc: 0.1051 - val_loss: 3.9569 - val_acc: 0.0881\n",
      "Epoch 107/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 3.8378 - acc: 0.1053 - val_loss: 3.9568 - val_acc: 0.0854\n",
      "Epoch 108/400\n",
      "32449/32449 [==============================] - 11s 339us/step - loss: 3.8359 - acc: 0.1046 - val_loss: 3.9555 - val_acc: 0.0853\n",
      "Epoch 109/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8340 - acc: 0.1059 - val_loss: 3.9547 - val_acc: 0.0887\n",
      "Epoch 110/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8322 - acc: 0.1052 - val_loss: 3.9542 - val_acc: 0.0876\n",
      "Epoch 111/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8306 - acc: 0.1058 - val_loss: 3.9527 - val_acc: 0.0848\n",
      "Epoch 112/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8287 - acc: 0.1067 - val_loss: 3.9524 - val_acc: 0.0852\n",
      "Epoch 113/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8269 - acc: 0.1064 - val_loss: 3.9523 - val_acc: 0.0869\n",
      "Epoch 114/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.8253 - acc: 0.1069 - val_loss: 3.9517 - val_acc: 0.0864\n",
      "Epoch 115/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8234 - acc: 0.1068 - val_loss: 3.9515 - val_acc: 0.0876\n",
      "Epoch 116/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8219 - acc: 0.1075 - val_loss: 3.9521 - val_acc: 0.0868\n",
      "Epoch 117/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8200 - acc: 0.1069 - val_loss: 3.9512 - val_acc: 0.0863\n",
      "Epoch 118/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8185 - acc: 0.1071 - val_loss: 3.9488 - val_acc: 0.0880\n",
      "Epoch 119/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.8170 - acc: 0.1080 - val_loss: 3.9488 - val_acc: 0.0855\n",
      "Epoch 120/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.8152 - acc: 0.1088 - val_loss: 3.9482 - val_acc: 0.0871\n",
      "Epoch 121/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8136 - acc: 0.1082 - val_loss: 3.9480 - val_acc: 0.0849\n",
      "Epoch 122/400\n",
      "32449/32449 [==============================] - 8s 241us/step - loss: 3.8120 - acc: 0.1089 - val_loss: 3.9477 - val_acc: 0.0884\n",
      "Epoch 123/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8105 - acc: 0.1083 - val_loss: 3.9481 - val_acc: 0.0860\n",
      "Epoch 124/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8088 - acc: 0.1089 - val_loss: 3.9478 - val_acc: 0.0886\n",
      "Epoch 125/400\n",
      "32449/32449 [==============================] - 8s 260us/step - loss: 3.8075 - acc: 0.1095 - val_loss: 3.9472 - val_acc: 0.0841\n",
      "Epoch 126/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.8060 - acc: 0.1091 - val_loss: 3.9457 - val_acc: 0.0873\n",
      "Epoch 127/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8045 - acc: 0.1108 - val_loss: 3.9456 - val_acc: 0.0885\n",
      "Epoch 128/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.8029 - acc: 0.1106 - val_loss: 3.9447 - val_acc: 0.0867\n",
      "Epoch 129/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.8011 - acc: 0.1109 - val_loss: 3.9455 - val_acc: 0.0863\n",
      "Epoch 130/400\n",
      "32449/32449 [==============================] - 8s 260us/step - loss: 3.8001 - acc: 0.1101 - val_loss: 3.9459 - val_acc: 0.0869\n",
      "Epoch 131/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7984 - acc: 0.1112 - val_loss: 3.9453 - val_acc: 0.0865\n",
      "Epoch 132/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7971 - acc: 0.1117 - val_loss: 3.9438 - val_acc: 0.0870\n",
      "Epoch 133/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7957 - acc: 0.1110 - val_loss: 3.9445 - val_acc: 0.0868\n",
      "Epoch 134/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7941 - acc: 0.1114 - val_loss: 3.9458 - val_acc: 0.0849\n",
      "Epoch 135/400\n",
      "32449/32449 [==============================] - 13s 389us/step - loss: 3.7931 - acc: 0.1128 - val_loss: 3.9440 - val_acc: 0.0863\n",
      "Epoch 136/400\n",
      "32449/32449 [==============================] - 12s 379us/step - loss: 3.7911 - acc: 0.1127 - val_loss: 3.9423 - val_acc: 0.0878\n",
      "Epoch 137/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7900 - acc: 0.1130 - val_loss: 3.9449 - val_acc: 0.0816\n",
      "Epoch 138/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7885 - acc: 0.1127 - val_loss: 3.9439 - val_acc: 0.0875\n",
      "Epoch 139/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7872 - acc: 0.1120 - val_loss: 3.9429 - val_acc: 0.0870\n",
      "Epoch 140/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7858 - acc: 0.1129 - val_loss: 3.9455 - val_acc: 0.0880\n",
      "Epoch 141/400\n",
      "32449/32449 [==============================] - 13s 388us/step - loss: 3.7848 - acc: 0.1122 - val_loss: 3.9432 - val_acc: 0.0869\n",
      "Epoch 142/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7833 - acc: 0.1135 - val_loss: 3.9428 - val_acc: 0.0858\n",
      "Epoch 143/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7820 - acc: 0.1151 - val_loss: 3.9434 - val_acc: 0.0855\n",
      "Epoch 144/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7805 - acc: 0.1151 - val_loss: 3.9444 - val_acc: 0.0847\n",
      "Epoch 145/400\n",
      "32449/32449 [==============================] - 13s 392us/step - loss: 3.7792 - acc: 0.1139 - val_loss: 3.9428 - val_acc: 0.0874\n",
      "Epoch 146/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7779 - acc: 0.1138 - val_loss: 3.9416 - val_acc: 0.0862\n",
      "Epoch 147/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7766 - acc: 0.1140 - val_loss: 3.9429 - val_acc: 0.0858\n",
      "Epoch 148/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7753 - acc: 0.1143 - val_loss: 3.9427 - val_acc: 0.0833\n",
      "Epoch 149/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7739 - acc: 0.1149 - val_loss: 3.9421 - val_acc: 0.0867\n",
      "Epoch 150/400\n",
      "32449/32449 [==============================] - 13s 387us/step - loss: 3.7728 - acc: 0.1154 - val_loss: 3.9429 - val_acc: 0.0837\n",
      "Epoch 151/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7713 - acc: 0.1163 - val_loss: 3.9432 - val_acc: 0.0846\n",
      "Epoch 152/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7703 - acc: 0.1152 - val_loss: 3.9420 - val_acc: 0.0855\n",
      "Epoch 153/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7688 - acc: 0.1162 - val_loss: 3.9432 - val_acc: 0.0869\n",
      "Epoch 154/400\n",
      "32449/32449 [==============================] - 13s 395us/step - loss: 3.7678 - acc: 0.1156 - val_loss: 3.9433 - val_acc: 0.0846\n",
      "Epoch 155/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7664 - acc: 0.1157 - val_loss: 3.9420 - val_acc: 0.0869\n",
      "Epoch 156/400\n",
      "32449/32449 [==============================] - 12s 385us/step - loss: 3.7650 - acc: 0.1165 - val_loss: 3.9432 - val_acc: 0.0871\n",
      "Epoch 157/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7641 - acc: 0.1170 - val_loss: 3.9426 - val_acc: 0.0874\n",
      "Epoch 158/400\n",
      "32449/32449 [==============================] - 11s 350us/step - loss: 3.7630 - acc: 0.1171 - val_loss: 3.9430 - val_acc: 0.0881\n",
      "Epoch 159/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7617 - acc: 0.1165 - val_loss: 3.9427 - val_acc: 0.0850\n",
      "Epoch 160/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7601 - acc: 0.1179 - val_loss: 3.9415 - val_acc: 0.0868\n",
      "Epoch 161/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.7590 - acc: 0.1188 - val_loss: 3.9424 - val_acc: 0.0850\n",
      "Epoch 162/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7581 - acc: 0.1173 - val_loss: 3.9428 - val_acc: 0.0844\n",
      "Epoch 163/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7565 - acc: 0.1187 - val_loss: 3.9424 - val_acc: 0.0858\n",
      "Epoch 164/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7554 - acc: 0.1178 - val_loss: 3.9441 - val_acc: 0.0820\n",
      "Epoch 165/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.7538 - acc: 0.1186 - val_loss: 3.9423 - val_acc: 0.0850\n",
      "Epoch 166/400\n",
      "32449/32449 [==============================] - 8s 259us/step - loss: 3.7528 - acc: 0.1191 - val_loss: 3.9431 - val_acc: 0.0839\n",
      "Epoch 167/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.7517 - acc: 0.1193 - val_loss: 3.9421 - val_acc: 0.0864\n",
      "Epoch 168/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7504 - acc: 0.1194 - val_loss: 3.9414 - val_acc: 0.0844\n",
      "Epoch 169/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7490 - acc: 0.1208 - val_loss: 3.9413 - val_acc: 0.0864\n",
      "Epoch 170/400\n",
      "32449/32449 [==============================] - 8s 258us/step - loss: 3.7478 - acc: 0.1190 - val_loss: 3.9420 - val_acc: 0.0854\n",
      "Epoch 171/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7471 - acc: 0.1193 - val_loss: 3.9420 - val_acc: 0.0854\n",
      "Epoch 172/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7454 - acc: 0.1197 - val_loss: 3.9419 - val_acc: 0.0836\n",
      "Epoch 173/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.7442 - acc: 0.1207 - val_loss: 3.9421 - val_acc: 0.0862\n",
      "Epoch 174/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7433 - acc: 0.1211 - val_loss: 3.9426 - val_acc: 0.0860\n",
      "Epoch 175/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7418 - acc: 0.1205 - val_loss: 3.9422 - val_acc: 0.0858\n",
      "Epoch 176/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.7404 - acc: 0.1209 - val_loss: 3.9432 - val_acc: 0.0867\n",
      "Epoch 177/400\n",
      "32449/32449 [==============================] - 8s 242us/step - loss: 3.7396 - acc: 0.1212 - val_loss: 3.9433 - val_acc: 0.0874\n",
      "Epoch 178/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7379 - acc: 0.1224 - val_loss: 3.9450 - val_acc: 0.0838\n",
      "Epoch 179/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7371 - acc: 0.1221 - val_loss: 3.9433 - val_acc: 0.0852\n",
      "Epoch 180/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.7360 - acc: 0.1229 - val_loss: 3.9450 - val_acc: 0.0833\n",
      "Epoch 181/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7350 - acc: 0.1225 - val_loss: 3.9440 - val_acc: 0.0854\n",
      "Epoch 182/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.7334 - acc: 0.1225 - val_loss: 3.9438 - val_acc: 0.0842\n",
      "Epoch 183/400\n",
      "32449/32449 [==============================] - 10s 298us/step - loss: 3.7322 - acc: 0.1223 - val_loss: 3.9431 - val_acc: 0.0874\n",
      "Epoch 184/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7312 - acc: 0.1233 - val_loss: 3.9435 - val_acc: 0.0854\n",
      "Epoch 185/400\n",
      "32449/32449 [==============================] - 12s 382us/step - loss: 3.7300 - acc: 0.1223 - val_loss: 3.9458 - val_acc: 0.0838\n",
      "Epoch 186/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7290 - acc: 0.1232 - val_loss: 3.9438 - val_acc: 0.0863\n",
      "Epoch 187/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7277 - acc: 0.1235 - val_loss: 3.9436 - val_acc: 0.0852\n",
      "Epoch 188/400\n",
      "32449/32449 [==============================] - 12s 384us/step - loss: 3.7265 - acc: 0.1246 - val_loss: 3.9432 - val_acc: 0.0854\n",
      "Epoch 189/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7255 - acc: 0.1237 - val_loss: 3.9435 - val_acc: 0.0858\n",
      "Epoch 190/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7239 - acc: 0.1249 - val_loss: 3.9443 - val_acc: 0.0860\n",
      "Epoch 191/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7226 - acc: 0.1238 - val_loss: 3.9454 - val_acc: 0.0834\n",
      "Epoch 192/400\n",
      "32449/32449 [==============================] - 13s 387us/step - loss: 3.7214 - acc: 0.1247 - val_loss: 3.9453 - val_acc: 0.0862\n",
      "Epoch 193/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7200 - acc: 0.1256 - val_loss: 3.9442 - val_acc: 0.0847\n",
      "Epoch 194/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7192 - acc: 0.1261 - val_loss: 3.9449 - val_acc: 0.0862\n",
      "Epoch 195/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7177 - acc: 0.1249 - val_loss: 3.9443 - val_acc: 0.0847\n",
      "Epoch 196/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7168 - acc: 0.1261 - val_loss: 3.9473 - val_acc: 0.0817\n",
      "Epoch 197/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7155 - acc: 0.1270 - val_loss: 3.9447 - val_acc: 0.0848\n",
      "Epoch 198/400\n",
      "32449/32449 [==============================] - 13s 392us/step - loss: 3.7146 - acc: 0.1276 - val_loss: 3.9454 - val_acc: 0.0864\n",
      "Epoch 199/400\n",
      "32449/32449 [==============================] - 12s 380us/step - loss: 3.7131 - acc: 0.1262 - val_loss: 3.9457 - val_acc: 0.0854\n",
      "Epoch 200/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7120 - acc: 0.1267 - val_loss: 3.9443 - val_acc: 0.0837\n",
      "Epoch 201/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7104 - acc: 0.1279 - val_loss: 3.9457 - val_acc: 0.0853\n",
      "Epoch 202/400\n",
      "32449/32449 [==============================] - 13s 389us/step - loss: 3.7093 - acc: 0.1293 - val_loss: 3.9475 - val_acc: 0.0879\n",
      "Epoch 203/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7084 - acc: 0.1280 - val_loss: 3.9463 - val_acc: 0.0868\n",
      "Epoch 204/400\n",
      "32449/32449 [==============================] - 12s 381us/step - loss: 3.7072 - acc: 0.1269 - val_loss: 3.9458 - val_acc: 0.0854\n",
      "Epoch 205/400\n",
      "32449/32449 [==============================] - 11s 326us/step - loss: 3.7058 - acc: 0.1284 - val_loss: 3.9463 - val_acc: 0.0849\n",
      "Epoch 206/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.7046 - acc: 0.1294 - val_loss: 3.9469 - val_acc: 0.0855\n",
      "Epoch 207/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.7033 - acc: 0.1297 - val_loss: 3.9477 - val_acc: 0.0874\n",
      "Epoch 208/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.7019 - acc: 0.1299 - val_loss: 3.9492 - val_acc: 0.0832\n",
      "Epoch 209/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.7009 - acc: 0.1297 - val_loss: 3.9455 - val_acc: 0.0858\n",
      "Epoch 210/400\n",
      "32449/32449 [==============================] - 9s 268us/step - loss: 3.6996 - acc: 0.1305 - val_loss: 3.9508 - val_acc: 0.0814\n",
      "Epoch 211/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6987 - acc: 0.1301 - val_loss: 3.9468 - val_acc: 0.0849\n",
      "Epoch 212/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6972 - acc: 0.1314 - val_loss: 3.9469 - val_acc: 0.0862\n",
      "Epoch 213/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6961 - acc: 0.1317 - val_loss: 3.9477 - val_acc: 0.0850\n",
      "Epoch 214/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6945 - acc: 0.1325 - val_loss: 3.9471 - val_acc: 0.0852\n",
      "Epoch 215/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.6936 - acc: 0.1317 - val_loss: 3.9491 - val_acc: 0.0816\n",
      "Epoch 216/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6922 - acc: 0.1324 - val_loss: 3.9487 - val_acc: 0.0871\n",
      "Epoch 217/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6911 - acc: 0.1329 - val_loss: 3.9488 - val_acc: 0.0839\n",
      "Epoch 218/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6900 - acc: 0.1331 - val_loss: 3.9498 - val_acc: 0.0869\n",
      "Epoch 219/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6885 - acc: 0.1330 - val_loss: 3.9487 - val_acc: 0.0863\n",
      "Epoch 220/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6875 - acc: 0.1338 - val_loss: 3.9489 - val_acc: 0.0843\n",
      "Epoch 221/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6862 - acc: 0.1340 - val_loss: 3.9488 - val_acc: 0.0838\n",
      "Epoch 222/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6845 - acc: 0.1340 - val_loss: 3.9489 - val_acc: 0.0837\n",
      "Epoch 223/400\n",
      "32449/32449 [==============================] - 8s 253us/step - loss: 3.6837 - acc: 0.1339 - val_loss: 3.9488 - val_acc: 0.0873\n",
      "Epoch 224/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6823 - acc: 0.1337 - val_loss: 3.9503 - val_acc: 0.0858\n",
      "Epoch 225/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6811 - acc: 0.1352 - val_loss: 3.9506 - val_acc: 0.0852\n",
      "Epoch 226/400\n",
      "32449/32449 [==============================] - 8s 250us/step - loss: 3.6798 - acc: 0.1354 - val_loss: 3.9509 - val_acc: 0.0833\n",
      "Epoch 227/400\n",
      "32449/32449 [==============================] - 8s 253us/step - loss: 3.6785 - acc: 0.1362 - val_loss: 3.9521 - val_acc: 0.0870\n",
      "Epoch 228/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6774 - acc: 0.1370 - val_loss: 3.9509 - val_acc: 0.0822\n",
      "Epoch 229/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6759 - acc: 0.1356 - val_loss: 3.9514 - val_acc: 0.0842\n",
      "Epoch 230/400\n",
      "32449/32449 [==============================] - 10s 297us/step - loss: 3.6748 - acc: 0.1364 - val_loss: 3.9500 - val_acc: 0.0853\n",
      "Epoch 231/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6734 - acc: 0.1358 - val_loss: 3.9515 - val_acc: 0.0832\n",
      "Epoch 232/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6719 - acc: 0.1371 - val_loss: 3.9510 - val_acc: 0.0857\n",
      "Epoch 233/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6708 - acc: 0.1375 - val_loss: 3.9521 - val_acc: 0.0827\n",
      "Epoch 234/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6693 - acc: 0.1378 - val_loss: 3.9524 - val_acc: 0.0848\n",
      "Epoch 235/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6682 - acc: 0.1378 - val_loss: 3.9530 - val_acc: 0.0843\n",
      "Epoch 236/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6667 - acc: 0.1383 - val_loss: 3.9531 - val_acc: 0.0837\n",
      "Epoch 237/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6655 - acc: 0.1387 - val_loss: 3.9529 - val_acc: 0.0830\n",
      "Epoch 238/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6645 - acc: 0.1380 - val_loss: 3.9527 - val_acc: 0.0828\n",
      "Epoch 239/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6627 - acc: 0.1398 - val_loss: 3.9537 - val_acc: 0.0834\n",
      "Epoch 240/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6619 - acc: 0.1396 - val_loss: 3.9545 - val_acc: 0.0821\n",
      "Epoch 241/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.6603 - acc: 0.1392 - val_loss: 3.9540 - val_acc: 0.0846\n",
      "Epoch 242/400\n",
      "32449/32449 [==============================] - 8s 255us/step - loss: 3.6591 - acc: 0.1416 - val_loss: 3.9558 - val_acc: 0.0825\n",
      "Epoch 243/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 3.6573 - acc: 0.1410 - val_loss: 3.9550 - val_acc: 0.0816\n",
      "Epoch 244/400\n",
      "32449/32449 [==============================] - 11s 336us/step - loss: 3.6563 - acc: 0.1407 - val_loss: 3.9568 - val_acc: 0.0815\n",
      "Epoch 245/400\n",
      "32449/32449 [==============================] - 10s 316us/step - loss: 3.6549 - acc: 0.1412 - val_loss: 3.9546 - val_acc: 0.0841\n",
      "Epoch 246/400\n",
      "32449/32449 [==============================] - 11s 331us/step - loss: 3.6537 - acc: 0.1416 - val_loss: 3.9547 - val_acc: 0.0830\n",
      "Epoch 247/400\n",
      "32449/32449 [==============================] - 11s 331us/step - loss: 3.6523 - acc: 0.1416 - val_loss: 3.9556 - val_acc: 0.0816\n",
      "Epoch 248/400\n",
      "32449/32449 [==============================] - 12s 369us/step - loss: 3.6509 - acc: 0.1434 - val_loss: 3.9570 - val_acc: 0.0846\n",
      "Epoch 249/400\n",
      "32449/32449 [==============================] - 12s 370us/step - loss: 3.6495 - acc: 0.1436 - val_loss: 3.9560 - val_acc: 0.0858\n",
      "Epoch 250/400\n",
      "32449/32449 [==============================] - 12s 370us/step - loss: 3.6482 - acc: 0.1426 - val_loss: 3.9550 - val_acc: 0.0855\n",
      "Epoch 251/400\n",
      "32449/32449 [==============================] - 12s 370us/step - loss: 3.6470 - acc: 0.1437 - val_loss: 3.9572 - val_acc: 0.0848\n",
      "Epoch 252/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 3.6452 - acc: 0.1444 - val_loss: 3.9566 - val_acc: 0.0836\n",
      "Epoch 253/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 3.6439 - acc: 0.1440 - val_loss: 3.9576 - val_acc: 0.0853\n",
      "Epoch 254/400\n",
      "32449/32449 [==============================] - 12s 370us/step - loss: 3.6432 - acc: 0.1441 - val_loss: 3.9573 - val_acc: 0.0831\n",
      "Epoch 255/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.6411 - acc: 0.1448 - val_loss: 3.9571 - val_acc: 0.0806\n",
      "Epoch 256/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.6398 - acc: 0.1450 - val_loss: 3.9574 - val_acc: 0.0816\n",
      "Epoch 257/400\n",
      "32449/32449 [==============================] - 8s 253us/step - loss: 3.6382 - acc: 0.1471 - val_loss: 3.9609 - val_acc: 0.0794\n",
      "Epoch 258/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6374 - acc: 0.1472 - val_loss: 3.9593 - val_acc: 0.0831\n",
      "Epoch 259/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6357 - acc: 0.1463 - val_loss: 3.9605 - val_acc: 0.0827\n",
      "Epoch 260/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.6344 - acc: 0.1460 - val_loss: 3.9608 - val_acc: 0.0823\n",
      "Epoch 261/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6331 - acc: 0.1454 - val_loss: 3.9639 - val_acc: 0.0871\n",
      "Epoch 262/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6315 - acc: 0.1477 - val_loss: 3.9613 - val_acc: 0.0847\n",
      "Epoch 263/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6300 - acc: 0.1481 - val_loss: 3.9595 - val_acc: 0.0830\n",
      "Epoch 264/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6288 - acc: 0.1480 - val_loss: 3.9641 - val_acc: 0.0810\n",
      "Epoch 265/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6276 - acc: 0.1482 - val_loss: 3.9608 - val_acc: 0.0841\n",
      "Epoch 266/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.6256 - acc: 0.1490 - val_loss: 3.9638 - val_acc: 0.0795\n",
      "Epoch 267/400\n",
      "32449/32449 [==============================] - 8s 250us/step - loss: 3.6242 - acc: 0.1491 - val_loss: 3.9630 - val_acc: 0.0800\n",
      "Epoch 268/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6229 - acc: 0.1489 - val_loss: 3.9650 - val_acc: 0.0772\n",
      "Epoch 269/400\n",
      "32449/32449 [==============================] - 8s 260us/step - loss: 3.6218 - acc: 0.1498 - val_loss: 3.9627 - val_acc: 0.0838\n",
      "Epoch 270/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6205 - acc: 0.1490 - val_loss: 3.9629 - val_acc: 0.0830\n",
      "Epoch 271/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6184 - acc: 0.1509 - val_loss: 3.9669 - val_acc: 0.0811\n",
      "Epoch 272/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6176 - acc: 0.1506 - val_loss: 3.9640 - val_acc: 0.0832\n",
      "Epoch 273/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6156 - acc: 0.1525 - val_loss: 3.9640 - val_acc: 0.0833\n",
      "Epoch 274/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6141 - acc: 0.1517 - val_loss: 3.9630 - val_acc: 0.0836\n",
      "Epoch 275/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.6127 - acc: 0.1519 - val_loss: 3.9647 - val_acc: 0.0816\n",
      "Epoch 276/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6113 - acc: 0.1531 - val_loss: 3.9684 - val_acc: 0.0793\n",
      "Epoch 277/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6100 - acc: 0.1517 - val_loss: 3.9666 - val_acc: 0.0809\n",
      "Epoch 278/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6084 - acc: 0.1521 - val_loss: 3.9678 - val_acc: 0.0825\n",
      "Epoch 279/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6066 - acc: 0.1550 - val_loss: 3.9653 - val_acc: 0.0826\n",
      "Epoch 280/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6053 - acc: 0.1533 - val_loss: 3.9659 - val_acc: 0.0814\n",
      "Epoch 281/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.6037 - acc: 0.1546 - val_loss: 3.9688 - val_acc: 0.0846\n",
      "Epoch 282/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.6022 - acc: 0.1542 - val_loss: 3.9657 - val_acc: 0.0820\n",
      "Epoch 283/400\n",
      "32449/32449 [==============================] - 8s 254us/step - loss: 3.6008 - acc: 0.1561 - val_loss: 3.9701 - val_acc: 0.0860\n",
      "Epoch 284/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.5990 - acc: 0.1562 - val_loss: 3.9683 - val_acc: 0.0820\n",
      "Epoch 285/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.5975 - acc: 0.1548 - val_loss: 3.9695 - val_acc: 0.0836\n",
      "Epoch 286/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5953 - acc: 0.1565 - val_loss: 3.9701 - val_acc: 0.0842\n",
      "Epoch 287/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5941 - acc: 0.1561 - val_loss: 3.9694 - val_acc: 0.0823\n",
      "Epoch 288/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5932 - acc: 0.1558 - val_loss: 3.9740 - val_acc: 0.0870\n",
      "Epoch 289/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5915 - acc: 0.1565 - val_loss: 3.9701 - val_acc: 0.0805\n",
      "Epoch 290/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.5894 - acc: 0.1574 - val_loss: 3.9768 - val_acc: 0.0799\n",
      "Epoch 291/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5883 - acc: 0.1585 - val_loss: 3.9737 - val_acc: 0.0859\n",
      "Epoch 292/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5866 - acc: 0.1582 - val_loss: 3.9703 - val_acc: 0.0825\n",
      "Epoch 293/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5850 - acc: 0.1597 - val_loss: 3.9766 - val_acc: 0.0839\n",
      "Epoch 294/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5835 - acc: 0.1579 - val_loss: 3.9731 - val_acc: 0.0807\n",
      "Epoch 295/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5816 - acc: 0.1597 - val_loss: 3.9713 - val_acc: 0.0843\n",
      "Epoch 296/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.5803 - acc: 0.1599 - val_loss: 3.9727 - val_acc: 0.0849\n",
      "Epoch 297/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5784 - acc: 0.1600 - val_loss: 3.9737 - val_acc: 0.0834\n",
      "Epoch 298/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5765 - acc: 0.1607 - val_loss: 3.9729 - val_acc: 0.0822\n",
      "Epoch 299/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.5752 - acc: 0.1613 - val_loss: 3.9746 - val_acc: 0.0799\n",
      "Epoch 300/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5741 - acc: 0.1611 - val_loss: 3.9770 - val_acc: 0.0769\n",
      "Epoch 301/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5720 - acc: 0.1614 - val_loss: 3.9744 - val_acc: 0.0839\n",
      "Epoch 302/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5698 - acc: 0.1631 - val_loss: 3.9807 - val_acc: 0.0852\n",
      "Epoch 303/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5682 - acc: 0.1631 - val_loss: 3.9751 - val_acc: 0.0832\n",
      "Epoch 304/400\n",
      "32449/32449 [==============================] - 8s 260us/step - loss: 3.5669 - acc: 0.1635 - val_loss: 3.9778 - val_acc: 0.0796\n",
      "Epoch 305/400\n",
      "32449/32449 [==============================] - 12s 379us/step - loss: 3.5655 - acc: 0.1646 - val_loss: 3.9804 - val_acc: 0.0825\n",
      "Epoch 306/400\n",
      "32449/32449 [==============================] - 8s 258us/step - loss: 3.5633 - acc: 0.1642 - val_loss: 3.9786 - val_acc: 0.0818\n",
      "Epoch 307/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5616 - acc: 0.1642 - val_loss: 3.9783 - val_acc: 0.0822\n",
      "Epoch 308/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5600 - acc: 0.1635 - val_loss: 3.9843 - val_acc: 0.0821\n",
      "Epoch 309/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5583 - acc: 0.1657 - val_loss: 3.9816 - val_acc: 0.0802\n",
      "Epoch 310/400\n",
      "32449/32449 [==============================] - 8s 248us/step - loss: 3.5566 - acc: 0.1677 - val_loss: 3.9888 - val_acc: 0.0841\n",
      "Epoch 311/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5549 - acc: 0.1666 - val_loss: 3.9812 - val_acc: 0.0779\n",
      "Epoch 312/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.5527 - acc: 0.1682 - val_loss: 3.9821 - val_acc: 0.0844\n",
      "Epoch 313/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.5510 - acc: 0.1676 - val_loss: 3.9847 - val_acc: 0.0831\n",
      "Epoch 314/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.5498 - acc: 0.1677 - val_loss: 3.9839 - val_acc: 0.0853\n",
      "Epoch 315/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5475 - acc: 0.1676 - val_loss: 3.9881 - val_acc: 0.0768\n",
      "Epoch 316/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5469 - acc: 0.1677 - val_loss: 3.9825 - val_acc: 0.0818\n",
      "Epoch 317/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5440 - acc: 0.1684 - val_loss: 3.9841 - val_acc: 0.0795\n",
      "Epoch 318/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5424 - acc: 0.1707 - val_loss: 3.9864 - val_acc: 0.0839\n",
      "Epoch 319/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5406 - acc: 0.1690 - val_loss: 3.9870 - val_acc: 0.0778\n",
      "Epoch 320/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.5390 - acc: 0.1700 - val_loss: 3.9865 - val_acc: 0.0811\n",
      "Epoch 321/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5369 - acc: 0.1700 - val_loss: 3.9875 - val_acc: 0.0833\n",
      "Epoch 322/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5354 - acc: 0.1714 - val_loss: 3.9896 - val_acc: 0.0809\n",
      "Epoch 323/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5335 - acc: 0.1717 - val_loss: 3.9875 - val_acc: 0.0796\n",
      "Epoch 324/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5313 - acc: 0.1725 - val_loss: 3.9917 - val_acc: 0.0828\n",
      "Epoch 325/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.5294 - acc: 0.1719 - val_loss: 3.9893 - val_acc: 0.0814\n",
      "Epoch 326/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5277 - acc: 0.1727 - val_loss: 3.9885 - val_acc: 0.0817\n",
      "Epoch 327/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5260 - acc: 0.1729 - val_loss: 3.9909 - val_acc: 0.0821\n",
      "Epoch 328/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5234 - acc: 0.1727 - val_loss: 3.9968 - val_acc: 0.0841\n",
      "Epoch 329/400\n",
      "32449/32449 [==============================] - 8s 252us/step - loss: 3.5224 - acc: 0.1749 - val_loss: 3.9959 - val_acc: 0.0794\n",
      "Epoch 330/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5207 - acc: 0.1754 - val_loss: 3.9939 - val_acc: 0.0748\n",
      "Epoch 331/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5183 - acc: 0.1771 - val_loss: 3.9929 - val_acc: 0.0831\n",
      "Epoch 332/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5161 - acc: 0.1756 - val_loss: 3.9946 - val_acc: 0.0791\n",
      "Epoch 333/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5143 - acc: 0.1766 - val_loss: 3.9926 - val_acc: 0.0799\n",
      "Epoch 334/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5129 - acc: 0.1774 - val_loss: 3.9953 - val_acc: 0.0793\n",
      "Epoch 335/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.5102 - acc: 0.1770 - val_loss: 3.9965 - val_acc: 0.0786\n",
      "Epoch 336/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5082 - acc: 0.1774 - val_loss: 3.9949 - val_acc: 0.0777\n",
      "Epoch 337/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5066 - acc: 0.1792 - val_loss: 4.0006 - val_acc: 0.0758\n",
      "Epoch 338/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.5046 - acc: 0.1798 - val_loss: 3.9983 - val_acc: 0.0768\n",
      "Epoch 339/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5019 - acc: 0.1792 - val_loss: 4.0067 - val_acc: 0.0751\n",
      "Epoch 340/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.5005 - acc: 0.1804 - val_loss: 4.0023 - val_acc: 0.0822\n",
      "Epoch 341/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.4981 - acc: 0.1811 - val_loss: 4.0080 - val_acc: 0.0774\n",
      "Epoch 342/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4968 - acc: 0.1794 - val_loss: 3.9997 - val_acc: 0.0783\n",
      "Epoch 343/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4948 - acc: 0.1810 - val_loss: 4.0042 - val_acc: 0.0749\n",
      "Epoch 344/400\n",
      "32449/32449 [==============================] - 8s 251us/step - loss: 3.4919 - acc: 0.1823 - val_loss: 4.0084 - val_acc: 0.0756\n",
      "Epoch 345/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4904 - acc: 0.1816 - val_loss: 4.0037 - val_acc: 0.0749\n",
      "Epoch 346/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4883 - acc: 0.1836 - val_loss: 4.0055 - val_acc: 0.0753\n",
      "Epoch 347/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4865 - acc: 0.1846 - val_loss: 4.0077 - val_acc: 0.0761\n",
      "Epoch 348/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4836 - acc: 0.1847 - val_loss: 4.0071 - val_acc: 0.0736\n",
      "Epoch 349/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4824 - acc: 0.1842 - val_loss: 4.0081 - val_acc: 0.0769\n",
      "Epoch 350/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4800 - acc: 0.1846 - val_loss: 4.0048 - val_acc: 0.0797\n",
      "Epoch 351/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4777 - acc: 0.1846 - val_loss: 4.0068 - val_acc: 0.0811\n",
      "Epoch 352/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4764 - acc: 0.1858 - val_loss: 4.0073 - val_acc: 0.0777\n",
      "Epoch 353/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4736 - acc: 0.1870 - val_loss: 4.0101 - val_acc: 0.0794\n",
      "Epoch 354/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4721 - acc: 0.1864 - val_loss: 4.0121 - val_acc: 0.0783\n",
      "Epoch 355/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4695 - acc: 0.1872 - val_loss: 4.0149 - val_acc: 0.0825\n",
      "Epoch 356/400\n",
      "32449/32449 [==============================] - 8s 250us/step - loss: 3.4685 - acc: 0.1876 - val_loss: 4.0143 - val_acc: 0.0790\n",
      "Epoch 357/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4655 - acc: 0.1888 - val_loss: 4.0135 - val_acc: 0.0775\n",
      "Epoch 358/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4636 - acc: 0.1891 - val_loss: 4.0144 - val_acc: 0.0797\n",
      "Epoch 359/400\n",
      "32449/32449 [==============================] - 8s 252us/step - loss: 3.4615 - acc: 0.1902 - val_loss: 4.0284 - val_acc: 0.0756\n",
      "Epoch 360/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4592 - acc: 0.1901 - val_loss: 4.0136 - val_acc: 0.0796\n",
      "Epoch 361/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4558 - acc: 0.1915 - val_loss: 4.0171 - val_acc: 0.0791\n",
      "Epoch 362/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4541 - acc: 0.1912 - val_loss: 4.0163 - val_acc: 0.0784\n",
      "Epoch 363/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4516 - acc: 0.1915 - val_loss: 4.0221 - val_acc: 0.0767\n",
      "Epoch 364/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4502 - acc: 0.1913 - val_loss: 4.0196 - val_acc: 0.0778\n",
      "Epoch 365/400\n",
      "32449/32449 [==============================] - 11s 347us/step - loss: 3.4472 - acc: 0.1928 - val_loss: 4.0183 - val_acc: 0.0794\n",
      "Epoch 366/400\n",
      "32449/32449 [==============================] - 12s 371us/step - loss: 3.4457 - acc: 0.1935 - val_loss: 4.0241 - val_acc: 0.0810\n",
      "Epoch 367/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4438 - acc: 0.1927 - val_loss: 4.0265 - val_acc: 0.0820\n",
      "Epoch 368/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4406 - acc: 0.1948 - val_loss: 4.0248 - val_acc: 0.0809\n",
      "Epoch 369/400\n",
      "32449/32449 [==============================] - 8s 244us/step - loss: 3.4372 - acc: 0.1964 - val_loss: 4.0279 - val_acc: 0.0767\n",
      "Epoch 370/400\n",
      "32449/32449 [==============================] - 8s 249us/step - loss: 3.4371 - acc: 0.1955 - val_loss: 4.0291 - val_acc: 0.0777\n",
      "Epoch 371/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4336 - acc: 0.1970 - val_loss: 4.0247 - val_acc: 0.0763\n",
      "Epoch 372/400\n",
      "32449/32449 [==============================] - 8s 245us/step - loss: 3.4310 - acc: 0.1978 - val_loss: 4.0299 - val_acc: 0.0767\n",
      "Epoch 373/400\n",
      "32449/32449 [==============================] - 8s 252us/step - loss: 3.4284 - acc: 0.1986 - val_loss: 4.0381 - val_acc: 0.0816\n",
      "Epoch 374/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4278 - acc: 0.1985 - val_loss: 4.0315 - val_acc: 0.0825\n",
      "Epoch 375/400\n",
      "32449/32449 [==============================] - 8s 243us/step - loss: 3.4243 - acc: 0.1990 - val_loss: 4.0323 - val_acc: 0.0764\n",
      "Epoch 376/400\n",
      "32449/32449 [==============================] - 11s 325us/step - loss: 3.4219 - acc: 0.1989 - val_loss: 4.0299 - val_acc: 0.0762\n",
      "Epoch 377/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.4193 - acc: 0.2013 - val_loss: 4.0429 - val_acc: 0.0749\n",
      "Epoch 378/400\n",
      "32449/32449 [==============================] - 12s 379us/step - loss: 3.4169 - acc: 0.2012 - val_loss: 4.0324 - val_acc: 0.0772\n",
      "Epoch 379/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.4146 - acc: 0.2016 - val_loss: 4.0368 - val_acc: 0.0751\n",
      "Epoch 380/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.4141 - acc: 0.2003 - val_loss: 4.0369 - val_acc: 0.0772\n",
      "Epoch 381/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.4104 - acc: 0.2021 - val_loss: 4.0396 - val_acc: 0.0778\n",
      "Epoch 382/400\n",
      "32449/32449 [==============================] - 12s 384us/step - loss: 3.4087 - acc: 0.2029 - val_loss: 4.0377 - val_acc: 0.0784\n",
      "Epoch 383/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.4046 - acc: 0.2034 - val_loss: 4.0639 - val_acc: 0.0693\n",
      "Epoch 384/400\n",
      "32449/32449 [==============================] - 13s 390us/step - loss: 3.4027 - acc: 0.2047 - val_loss: 4.0406 - val_acc: 0.0726\n",
      "Epoch 385/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.3991 - acc: 0.2049 - val_loss: 4.0392 - val_acc: 0.0764\n",
      "Epoch 386/400\n",
      "32449/32449 [==============================] - 12s 378us/step - loss: 3.3975 - acc: 0.2059 - val_loss: 4.0470 - val_acc: 0.0777\n",
      "Epoch 387/400\n",
      "11000/32449 [=========>....................] - ETA: 8s - loss: 3.3894 - acc: 0.2100"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e86a8991d720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-ff13ed5d31b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     47\u001b[0m                        \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVerbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                        validation_split=self.Validation_split)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-2018.12/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = my_Net()\n",
    " \n",
    "net.make_model()\n",
    " \n",
    "net.train(X_train, y_train)\n",
    "    \n",
    "score = net.score(X_test, y_test)\n",
    " \n",
    "print(\"\\nTest loss:\", score[0])\n",
    "print(\"\\nTest accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルを保存\n",
    "model_save = False\n",
    "if model_save :\n",
    "    model_path=os.path.join(os.environ['BR_HOME'],\"boatrace/models\")\n",
    "    model_modelfile=os.path.join(model_path,'keras_perceptron_model.json')\n",
    "    model_weightfile=os.path.join(model_path,'keras_perceptron_weight.json')\n",
    "\n",
    "    open(model_modelfile,\"w\").write(net.model.to_json())\n",
    "    net.model.save_weights(model_weightfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testの回収率をシミュレート\n",
    "# オッズを見て判断する場合\n",
    "resAmount=0\n",
    "buyAmount=0\n",
    "resCnt=0\n",
    "buyCnt=0\n",
    "\n",
    "testPredictList=net.model.predict(X_test,batch_size=len(X_test))\n",
    "\n",
    "for i in range(len(raceId_test) ):\n",
    "    raceId=raceId_test[i]\n",
    "    with dbh.cursor() as cursor:\n",
    "        sel_sql = \"select funaken,odds from raceodds \\\n",
    "                   where oddsType = '3t' \\\n",
    "                   and raceId = '%s' \\\n",
    "                   order by funaken\" \\\n",
    "                   % (raceId)\n",
    "\n",
    "        cursor.execute(sel_sql)\n",
    "        loadList=pd.DataFrame(cursor.fetchall())\n",
    "        loadList=pd.DataFrame(loadList.replace(funakenDict))\n",
    "                \n",
    "    for j in range(120):\n",
    "        # y_predの閾値を下げてみる。\n",
    "        if testPredictList[i][j]> 0.05 and ( (testPredictList[i][j] * (loadList[loadList['funaken']==j]['odds'])).values[0] > 2.0) :\n",
    "            print(\"buy:\",raceId,i,j,loadList[loadList['funaken']==j]['odds'].values[0],round(testPredictList[i][j],3) )\n",
    "            buyAmount+=1\n",
    "            buyCnt+=1\n",
    "            if list(y_test[i]).index(1)==j:\n",
    "                print(\"☆hit!☆:\",raceId,j,loadList[loadList['funaken']==j]['odds'].values[0])\n",
    "                resAmount += o_test[i]\n",
    "                resCnt+=1\n",
    "            else:\n",
    "                pass\n",
    "#res=net.model.predict_on_batch(xdf[1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"resultReturn:\",resAmount/buyAmount)\n",
    "print(\"totalRace,buy,return\",len(y_test),buyAmount,resAmount )\n",
    "print(\"rate:\",resCnt/buyCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
